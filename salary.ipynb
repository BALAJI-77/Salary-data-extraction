{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscraping\n",
    "import requests\n",
    "import html\n",
    "\n",
    "url = 'http://quotes.toscrape.com'\n",
    "response = requests.get(url)    # shows the response(200)\n",
    "print(response)\n",
    "\n",
    "html = response.text\n",
    "print(html)\n",
    "# title =  response.html.find('title')\n",
    "# print(title)\n",
    "\n",
    "# author = html1.find('small', {'class': 'author'})\n",
    "# print(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import requests\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "# import pandas as pd\n",
    "# from openpyxl import Workbook\n",
    "# import pandas as pd\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_extension('adblocker.crx')\n",
    "driver= webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "def retry(func, retries=3):\n",
    "    def retry_wrapper(*args, **kwargs):\n",
    "        attempts = 0\n",
    "        while attempts < retries:\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(e)\n",
    "                time.sleep(2)\n",
    "                attempts += 1\n",
    "\n",
    "    return retry_wrapper\n",
    "\n",
    "@retry\n",
    "def go_to_url(url):\n",
    "    get_url=url\n",
    "    driver.get(get_url)\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    print(url)\n",
    "    return url\n",
    "    # print(Fore.RED + 'This text is red in color')\n",
    "    \n",
    "# go_to_url('https://www.listcompany.org/Australia_Country.html')\n",
    "if __name__ == '__main__':\n",
    "    all_links=['https://www.linkedin.com/salaryjsajdjajbsja',\n",
    "            'https://www.indeed.com/career/sales-associate/salaries'\n",
    "            'https://www.payscale.com/research/US/Job']\n",
    "    for links in all_links:\n",
    "        text=go_to_url(links)  \n",
    "        print(\"URL = \",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import exception\n",
    "from urllib import response\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import requests\n",
    "from colorama import Fore\n",
    "# from retrying import retry\n",
    "from retry import retry\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_extension('adblocker.crx')  \n",
    "# driver= webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "\n",
    "# @retry(wait_exponential_multiplier=1000, wait_exponential_max=10000, stop_max_delay=30000)\n",
    "# @retry((ValueError,TypeError), delay=5, tries=6, backoff=1, jitter=0)\n",
    "@retry(exceptions=Exception, delay=5, tries=2)\n",
    "def get_data(url):\n",
    "    try:\n",
    "        result = requests.get(url)\n",
    "        print(url)\n",
    "        print(result,'------++++++++')\n",
    "        response_status = str.__contains__(str(result), '200')\n",
    "        print(response_status)\n",
    "        # raise TypeError('ErrorMessages.STATUS_TIMEOUT_MESSAGE')\n",
    "        if str(response_status) == 'True':\n",
    "            driver = webdriver.Chrome(options=options)\n",
    "            driver.get(url)\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            print('success')\n",
    "        # elif str(response_status) == 'False':\n",
    "        #     # raise TypeError('ErrorMessages.STATUS_TIMEOUT_MESSAGE')\n",
    "        #     raise\n",
    "        else:\n",
    "            raise\n",
    "    except:\n",
    "        print('error')\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # text = get_data('https://httpbin.org/html')\n",
    "    all_links=['https://www.linkedin.com/salaryjsajdjajbsja',\n",
    "        'https://www.indeed.com/career/sales-associate/salaries',\n",
    "        'https://www.payscale.com/research/US/Job']\n",
    "    for links in all_links:\n",
    "        text=get_data(links)  \n",
    "        print(\"URL = \",text)\n",
    "    # text = get_data('https://pleasesubtome.org/html')\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import exception\n",
    "from os import link\n",
    "from urllib import response\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import requests\n",
    "from colorama import Fore\n",
    "# from retrying import retry\n",
    "from retry import retry\n",
    "from retry.api import retry_call\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_extension('adblocker.crx')  \n",
    "\n",
    "# @retry(exceptions=Exception, delay=5, tries=2)\n",
    "# def get_data(url):\n",
    "def get_data(service, info=None):\n",
    "    print(service)\n",
    "    try:\n",
    "        result = requests.get(service)\n",
    "        print(service)\n",
    "        print(result,'------++++++++')\n",
    "        response_status = str.__contains__(str(result), '200')\n",
    "        print(response_status)\n",
    "        if str(response_status) != 'True':\n",
    "            raise\n",
    "        elif str(response_status) == 'True':\n",
    "            driver = webdriver.Chrome(options=options)\n",
    "            driver.get(service)\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            print('success')\n",
    "            pass\n",
    "    except Exception as error:\n",
    "        print('error','-------------->>>>>>>>>>>>')\n",
    "        # raise\n",
    "    finally:\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # text = get_data('https://httpbin.org/html')\n",
    "    all_links=['https://www.linkedin.com/salaryjsajdjajbsja',\n",
    "        'https://www.indeed.com/career/sales-associate/salaries',\n",
    "        'https://www.payscale.com/research/US/Job']\n",
    "    for links in all_links:\n",
    "        result = retry_call(get_data, fargs=[links], fkwargs={\"info\": None}, tries=2)\n",
    "        print(result)\n",
    "        text=get_data(links)  \n",
    "        print(\"URL = \",text)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import exception\n",
    "from os import link\n",
    "from urllib import response\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import requests\n",
    "from colorama import Fore\n",
    "# from retrying import retry\n",
    "from retry import retry\n",
    "from retry.api import retry_call\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_extension('adblocker.crx')  \n",
    "\n",
    "# @retry(exceptions=Exception, delay=5, tries=2)\n",
    "# def get_data(url):\n",
    "def get_data(url, info=None):\n",
    "    try:\n",
    "        result = requests.get(url)\n",
    "        print(url)\n",
    "        print(result,'------++++++++')\n",
    "        response_status = str.__contains__(str(result), '200')\n",
    "        print(response_status)\n",
    "        if str(response_status) != 'True':\n",
    "            raise TypeError\n",
    "        elif str(response_status) == 'True':\n",
    "            driver = webdriver.Chrome(options=options)\n",
    "            driver.get(url)\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            print('success')\n",
    "            # pass\n",
    "    except Exception as error:\n",
    "        print('error','-------------->>>>>>>>>>>>')\n",
    "        # raise\n",
    "    # finally:\n",
    "    #     pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # text = get_data('https://httpbin.org/html')\n",
    "    all_links=['https://www.linkedin.com/salaryjsajdjajbsja',\n",
    "        'https://www.indeed.com/career/sales-associate/salaries',\n",
    "        'https://www.payscale.com/research/US/Job']\n",
    "    for links in all_links:\n",
    "        result = retry_call(get_data, fargs=[links], fkwargs={\"info\": None},exceptions=TypeError, tries=2)\n",
    "        print(result)\n",
    "        text=get_data(links)  \n",
    "        print(\"URL = \",text)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import exception\n",
    "from os import link\n",
    "from urllib import response\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import requests\n",
    "from colorama import Fore\n",
    "# from retrying import retry\n",
    "from retry import retry\n",
    "from retry.api import retry_call\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_extension('adblocker.crx')  \n",
    "\n",
    "# @retry(exceptions=Exception, delay=5, tries=2)\n",
    "# def get_data(url):\n",
    "def get_data(url, info=None, tries=3):\n",
    "    attempts = 0\n",
    "    while attempts < tries:\n",
    "        try:\n",
    "            result = requests.get(url)\n",
    "            print(url)\n",
    "            print(result,'------++++++++')\n",
    "            response_status = str.__contains__(str(result), '200')\n",
    "            print(response_status)\n",
    "            if str(response_status) == 'True':\n",
    "                driver = webdriver.Chrome(options=options)\n",
    "                driver.get(url)\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                print('success')\n",
    "                # pass\n",
    "        except Exception as error:\n",
    "            print('error','-------------->>>>>>>>>>>>')\n",
    "            attempts += 1\n",
    "        # raise\n",
    "    # finally:\n",
    "    #     pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # text = get_data('https://httpbin.org/html')\n",
    "    all_links=['https://www.linkedin.com/salaryjsajdjajbsja',\n",
    "        'https://www.indeed.com/career/sales-associate/salaries',\n",
    "        'https://www.payscale.com/research/US/Job']\n",
    "    for links in all_links:\n",
    "        result = retry_call(get_data, fargs=[links], fkwargs={\"info\": None},exceptions=Exception,tries=3)\n",
    "        print(result)\n",
    "        text=get_data(links)  \n",
    "        print(\"URL = \",text)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASYNCRONOUS MODEL CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def bala():\n",
    "    print(\"hello\")\n",
    "    task1=asyncio.create_task(bala_1())\n",
    "    task2=asyncio.create_task(bala_2())\n",
    "    await task1\n",
    "    await task2\n",
    "    print('end')\n",
    "    \n",
    "async def bala_1():\n",
    "    print('22222')\n",
    "    await asyncio.sleep(5)\n",
    "    print('121212')\n",
    "\n",
    "async def bala_2():\n",
    "    await asyncio.sleep(1)\n",
    "    print('3333333333333')\n",
    "    await asyncio.sleep(7)\n",
    "    print('44444444')\n",
    "       \n",
    "    \n",
    "asyncio.run(bala())\n",
    "print('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 4\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import sleep\n",
    "import scrapy\n",
    "from selenium import webdriver  \n",
    "from scrapy.loader import ItemLoader\n",
    "from scrapy_project.items import Profile\n",
    "from scrapy import Request\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "\n",
    "class ProductSpider(scrapy.Spider):\n",
    "    name = \"scrapy2_spider\"\n",
    "    start_urls=[]\n",
    "    \n",
    "    url_collection = ['https://www.webmd.com/drugs/2/drug-53935/cold-tablet-oral/details',\n",
    "                  'https://www.geeksforgeeks.org/python-using-variable-outside-and-inside-the-class-and-method/',\n",
    "                  'https://www.bankbazaar.com/tax/how-calculate-income-tax-on-salary-with-example.html',\n",
    "                  'https://en.wikipedia.org/wiki/Main_Page',\n",
    "                  'https://wikimediafoundation.org/'\n",
    "                 ]\n",
    "    result_list=[]\n",
    "\n",
    "    def start_requests(self):\n",
    "        def get_page_data(url):\n",
    "            driver = webdriver.Chrome(\"D:\\Project\\scarpy-selenium\\chromedriver.exe\")\n",
    "            driver.get(url)\n",
    "            return_data = {}\n",
    "            try:\n",
    "                sleep(5)\n",
    "                return_data['title'] = driver.find_element_by_xpath('//title').get_attribute(\"innerHTML\")\n",
    "                return_data['url']=url\n",
    "            except:\n",
    "                print(\"Data extraction issue\")\n",
    "            \n",
    "            body = driver.page_source\n",
    "            response = HtmlResponse(url=driver.current_url, body=body, encoding='utf-8')\n",
    "            for value in response.xpath('//head'):\n",
    "                title=value.css('title::text').get(default='not-found')\n",
    "                temp_data={'url':response.url,'title':title}\n",
    "                self.result_list.append(temp_data)\n",
    "\n",
    "        def my_multithreading():        \n",
    "            with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "                return executor.map(get_page_data,self.url_collection,timeout = 60)\n",
    "\n",
    "        my_multithreading()\n",
    "        print(self.result_list)\n",
    "        return []\n",
    "    \n",
    "    def parse(self, response, **kwargs):\n",
    "        print('test ok')\n",
    "        print('===================>>>>>>>>>>>>>>>',response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "async and webbrowser working model code -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import exception\n",
    "from os import link\n",
    "from urllib import response\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import requests\n",
    "# from colorama import Fore\n",
    "import asyncio\n",
    "# from retrying import retry\n",
    "# from retry import retry\n",
    "# from retry.api import retry_call\n",
    "\n",
    "\n",
    "# ---- chrome browser ----\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_extension('adblocker.crx')  \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "#  ------ main function assign the asynchronous function into task ---------\n",
    "async def main():\n",
    "    website_1=asyncio.create_task(monster_website())\n",
    "    print('<<<<<<<<<<<<<<<<<<----------------------------->>>>>>>>>>>>>>>>>>')\n",
    "    website_2=asyncio.create_task(monster_website_2())\n",
    "    await website_1\n",
    "    await website_2\n",
    "    print('end')\n",
    "\n",
    "# ------- monster website for united state --------\n",
    "async def monster_website():\n",
    "    driver=webbrowser()\n",
    "    driver.get(\"https://www.monster.com/salary/\")\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    position=\"java full stack developer\"\n",
    "    await asyncio.sleep(4)\n",
    "    # time.sleep(4)\n",
    "    element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "    element.send_keys(position)\n",
    "    element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "    element1.send_keys(\"United States Military Acade, NY\")\n",
    "    # time.sleep(15)\n",
    "    await asyncio.sleep(15)\n",
    "    element.send_keys(Keys.ENTER)\n",
    "    element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "    element2.click()\n",
    "    # time.sleep(2)\n",
    "    await asyncio.sleep(2)\n",
    "    average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "    job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "    print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    " \n",
    "    \n",
    "# ----------  copy of monster website with different position   ---------------------  \n",
    "async def monster_website_2():\n",
    "    driver=webbrowser()\n",
    "    driver.get(\"https://www.monster.com/salary/\")\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    position=\"python developer\"\n",
    "    # time.sleep(4)\n",
    "    await asyncio.sleep(4)\n",
    "    element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "    element.send_keys(position)\n",
    "    element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "    element1.send_keys(\"United States Military Acade, NY\")\n",
    "    # time.sleep(15)\n",
    "    await asyncio.sleep(15)\n",
    "    element.send_keys(Keys.ENTER)\n",
    "    element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "    element2.click()\n",
    "    # time.sleep(2)\n",
    "    await asyncio.sleep(2)\n",
    "    average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "    job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "    print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "    \n",
    "    \n",
    "    \n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flask connected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, session\n",
    "from flask import Flask, jsonify, json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "import asyncio\n",
    "# from retrying import retry\n",
    "# from retry import retry\n",
    "# from retry.api import retry_call\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    data = request.get_json()\n",
    "    position =data.get('position')\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print(position)\n",
    "    return \"success\"\n",
    "\n",
    "# ---- chrome browser ----\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_extension('adblocker.crx')  \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "#  ------ main function assign the asynchronous function into task ---------\n",
    "async def main():\n",
    "    website_1=asyncio.create_task(monster_website())\n",
    "    print('<<<<<<<<<<<<<<<<<<----------------------------->>>>>>>>>>>>>>>>>>')\n",
    "    website_2=asyncio.create_task(monster_website_2())\n",
    "    await website_1\n",
    "    await website_2\n",
    "    print('end')\n",
    "\n",
    "# ------- monster website for united state --------\n",
    "async def monster_website():\n",
    "    driver=webbrowser()\n",
    "    driver.get(\"https://www.monster.com/salary/\")\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    position=\"java full stack developer\"\n",
    "    await asyncio.sleep(4)\n",
    "    # time.sleep(4)\n",
    "    element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "    element.send_keys(position)\n",
    "    element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "    element1.send_keys(\"United States Military Acade, NY\")\n",
    "    # time.sleep(15)\n",
    "    await asyncio.sleep(15)\n",
    "    element.send_keys(Keys.ENTER)\n",
    "    element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "    element2.click()\n",
    "    # time.sleep(2)\n",
    "    await asyncio.sleep(2)\n",
    "    average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "    job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "    print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    " \n",
    "    \n",
    "# ----------  copy of monster website with different position   ---------------------  \n",
    "async def monster_website_2():\n",
    "    driver=webbrowser()\n",
    "    driver.get(\"https://www.monster.com/salary/\")\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    position=\"python developer\"\n",
    "    # time.sleep(4)\n",
    "    await asyncio.sleep(4)\n",
    "    element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "    element.send_keys(position)\n",
    "    element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "    element1.send_keys(\"United States Military Acade, NY\")\n",
    "    # time.sleep(15)\n",
    "    await asyncio.sleep(15)\n",
    "    element.send_keys(Keys.ENTER)\n",
    "    element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "    element2.click()\n",
    "    # time.sleep(2)\n",
    "    await asyncio.sleep(2)\n",
    "    average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "    job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "    print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, session\n",
    "from flask import Flask, jsonify, json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "import asyncio\n",
    "# from retrying import retry\n",
    "# from retry import retry\n",
    "# from retry.api import retry_call\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    data = request.get_json()\n",
    "    position =data.get('position')\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print(position)\n",
    "    asyncio.run(main(name,position))\n",
    "    return \"success\"\n",
    "\n",
    "# ---- chrome browser ----\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_extension('adblocker.crx')  \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "#  ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    website_1=asyncio.create_task(monster_website())\n",
    "    print('<<<<<<<<<<<<<<<<<<----------------------------->>>>>>>>>>>>>>>>>>')\n",
    "    website_2=asyncio.create_task(monster_website_2())\n",
    "    await website_1\n",
    "    await website_2\n",
    "    print('end')\n",
    "\n",
    "# ------- monster website for united state --------\n",
    "async def monster_website():\n",
    "    driver=webbrowser()\n",
    "    driver.get(\"https://www.monster.com/salary/\")\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    position=\"java full stack developer\"\n",
    "    await asyncio.sleep(4)\n",
    "    # time.sleep(4)\n",
    "    element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "    element.send_keys(position)\n",
    "    element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "    element1.send_keys(\"United States Military Acade, NY\")\n",
    "    # time.sleep(15)\n",
    "    await asyncio.sleep(15)\n",
    "    element.send_keys(Keys.ENTER)\n",
    "    element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "    element2.click()\n",
    "    # time.sleep(2)\n",
    "    await asyncio.sleep(2)\n",
    "    average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "    job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "    print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    " \n",
    "    \n",
    "# ----------  copy of monster website with different position   ---------------------  \n",
    "async def monster_website_2():\n",
    "    driver=webbrowser()\n",
    "    driver.get(\"https://www.monster.com/salary/\")\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "    position=\"python developer\"\n",
    "    # time.sleep(4)\n",
    "    await asyncio.sleep(4)\n",
    "    element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "    element.send_keys(position)\n",
    "    element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "    element1.send_keys(\"United States Military Acade, NY\")\n",
    "    # time.sleep(15)\n",
    "    await asyncio.sleep(15)\n",
    "    element.send_keys(Keys.ENTER)\n",
    "    element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "    element2.click()\n",
    "    # time.sleep(2)\n",
    "    await asyncio.sleep(2)\n",
    "    average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "    job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "    print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, session\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "import asyncio\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    data = request.get_json()\n",
    "    position =data.get('position')\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print(position)\n",
    "    asyncio.run(main(name,position))\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "# def retry(func, retries=3):\n",
    "#     def retry_wrapper(*args, **kwargs):\n",
    "#         attempts = 0\n",
    "#         while attempts < retries:\n",
    "#             try:\n",
    "#                 print('----------------------------------success-------------------------------------')\n",
    "#                 return func(*args, **kwargs)\n",
    "#             except requests.exceptions.RequestException as e:\n",
    "#                 print(e)\n",
    "#                 time.sleep(2)\n",
    "#                 attempts += 1\n",
    "#     return retry_wrapper\n",
    "\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_extension('adblocker.crx')  \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    website_1=asyncio.create_task(monster_website())\n",
    "    # print('<<<<<<<<<<<<<<<<<<----------------------------->>>>>>>>>>>>>>>>>>')\n",
    "    website_2=asyncio.create_task(monster_website_2())\n",
    "    await website_1\n",
    "    await website_2\n",
    "    print('end')\n",
    "\n",
    "\n",
    "# ------------- monster website for united state ---------------\n",
    "# @retry\n",
    "async def monster_website():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        driver.get(\"https://www.monster.com/salary/\")\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        position=\"java full stack developer\"\n",
    "        await asyncio.sleep(4)\n",
    "        # time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        # time.sleep(15)\n",
    "        await asyncio.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        # time.sleep(2)\n",
    "        await asyncio.sleep(2)\n",
    "        average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "        job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   copy of monster website with different position   -----------------------\n",
    "# @retry\n",
    "async def monster_website_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        driver.get(\"https://www.monster.com/salary/\")\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        position=\"python developer\"\n",
    "        # time.sleep(4)\n",
    "        await asyncio.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        # time.sleep(15)\n",
    "        await asyncio.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        # time.sleep(2)\n",
    "        await asyncio.sleep(2)\n",
    "        average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "        job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "    # app.run(threaded=True ,processes=1)     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from logging import exception\n",
    "# import time\n",
    "\n",
    "# import requests\n",
    "\n",
    "\n",
    "# def retry(func, retries=3):\n",
    "#     def retry_wrapper(*args, **kwargs):\n",
    "#         attempts = 0\n",
    "#         while attempts < retries:\n",
    "#             try:\n",
    "#                 return func(*args, **kwargs)\n",
    "#             except requests.exceptions.RequestException as e:\n",
    "#                 print(e)\n",
    "#                 time.sleep(2)\n",
    "#                 attempts += 1\n",
    "\n",
    "#     return retry_wrapper\n",
    "\n",
    "\n",
    "# @retry\n",
    "# def get_data(url):\n",
    "#     print('----------------',exception)\n",
    "#     r = requests.get(url)\n",
    "#     # print('----------------',exception)\n",
    "#     # return r.text\n",
    "#     # return r.text\n",
    "    \n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # text = get_data('https://httpbin.org/html')\n",
    "#     text = get_data('https://pleasesubtome.org/htmlwuaidisfihasho')\n",
    "#     print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, session\n",
    "from flask_limiter import Limiter\n",
    "from flask_limiter.util import get_remote_address\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "import requests\n",
    "import asyncio\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------limit the number request can be made in flask --------------------------\n",
    "# limiter = Limiter(\n",
    "#     app,key_func=get_remote_address,default_limits=[\"1 per min\"])\n",
    "\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "# @limiter.limit(\"1 per minute\")\n",
    "def trigger():\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position')\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    asyncio.run(main(name,position))\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "# def retry(func, retries=3):\n",
    "#     def retry_wrapper(*args, **kwargs):\n",
    "#         attempts = 0\n",
    "#         while attempts < retries:\n",
    "#             try:\n",
    "#                 print('----------------------------------success-------------------------------------')\n",
    "#                 return func(*args, **kwargs)\n",
    "#             except requests.exceptions.RequestException as e:\n",
    "#                 print(e)\n",
    "#                 time.sleep(2)\n",
    "#                 attempts += 1\n",
    "#     return retry_wrapper\n",
    "\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_extension('adblocker.crx')  \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    website_1=asyncio.create_task(monster_website())\n",
    "    website_2=asyncio.create_task(glassdoor_india_2())\n",
    "    website_3=asyncio.create_task(indeed_us_3())\n",
    "    website_4=asyncio.create_task(linkedin_aus_4())\n",
    "    website_5=asyncio.create_task(linkedin_india_5())\n",
    "    website_6=asyncio.create_task(linkedin_us_6())\n",
    "    website_7=asyncio.create_task(payscale_AUS_Scrap_7())\n",
    "    website_8=asyncio.create_task(payscale_india_8())\n",
    "    website_9=asyncio.create_task(payscale_US_9())\n",
    "    website_10=asyncio.create_task(seek_scrapy_aus_10())\n",
    "    website_11=asyncio.create_task(talent_aus_scrapy_11())\n",
    "    website_12=asyncio.create_task(talent_india_12())\n",
    "    \n",
    "    await website_1\n",
    "    await website_2\n",
    "    await website_3\n",
    "    await website_4\n",
    "    await website_5\n",
    "    await website_6\n",
    "    await website_7\n",
    "    await website_8\n",
    "    await website_9\n",
    "    await website_10\n",
    "    await website_11\n",
    "    await website_12\n",
    "    \n",
    "    print('end')\n",
    "\n",
    "\n",
    "# ------------- monster website for united state ---------------\n",
    "async def monster_website():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        driver.get(\"https://www.monster.com/salary/\")\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # position=\"java full stack developer\"\n",
    "        await asyncio.sleep(4)\n",
    "        # time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        # time.sleep(15)\n",
    "        await asyncio.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        # time.sleep(2)\n",
    "        await asyncio.sleep(2)\n",
    "        average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "        job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "async def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        await asyncio.sleep(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        # time.sleep(2.0)\n",
    "        await asyncio.sleep(2)\n",
    "        print('2-------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!2222222222222!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "async def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        await asyncio.sleep(0.5)\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        # time.sleep(0.8)\n",
    "        await asyncio.sleep(0.8)\n",
    "        # select by visible text\n",
    "        select.select_by_visible_text('Per year')\n",
    "        #select by value \n",
    "        select.select_by_value('YEARLY')\n",
    "        # time.sleep(8.0)\n",
    "        await asyncio.sleep(0.8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('3------------------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!33333333333333!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "async def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        # time.sleep(2.0)\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('4------------------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!4444444444444444444!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        pass\n",
    "\n",
    "async def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # time.sleep(2.0)\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('5------------------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!55555555555555555!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        pass\n",
    "\n",
    "async def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        # time.sleep(2.0)\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        #time.sleep()\n",
    "        print(salary_content)\n",
    "        print('6------------------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!666666666666666666!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        pass\n",
    "\n",
    "#------check+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "async def payscale_AUS_Scrap_7():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"_\")\n",
    "        url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        # time.sleep(2.0)\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        #time.sleep()\n",
    "        print('7------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!777777777777777777777!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "#------check+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "async def payscale_india_8():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"_\")\n",
    "        url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('8------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!888888888888888888!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        pass\n",
    "\n",
    "async def payscale_US_9():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"_\")\n",
    "        url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('9------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!999999999999999999!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "# ----------------------- check ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=\n",
    "async def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        #time.sleep()\n",
    "        print('10------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!10101010101010101010!!!!!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        pass\n",
    "\n",
    "async def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        #time.sleep()\n",
    "        print('11------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!-11-11-11-11-11-!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "# ----------------------- check +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "async def talent_india_12():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "\n",
    "        print('12------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!-12-12-12-12-12-12-!!!!!!!!!!!!!!!!!')\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "    # app.run(threaded=True ,processes=1)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, session\n",
    "from flask_limiter import Limiter\n",
    "from flask_limiter.util import get_remote_address\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import Process\n",
    "import threading\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ---------------limit the number request can be made in flask --------------------------\n",
    "# limiter = Limiter(\n",
    "#     app,key_func=get_remote_address,default_limits=[\"1 per min\"])\n",
    "\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position')\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    # ProcessPoolExecutor(5)\n",
    "    asyncio.run(main(name,position))\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "# def retry(func, retries=3):\n",
    "#     def retry_wrapper(*args, **kwargs):\n",
    "#         attempts = 0\n",
    "#         while attempts < retries:\n",
    "#             try:\n",
    "#                 print('----------------------------------success-------------------------------------')\n",
    "#                 return func(*args, **kwargs)\n",
    "#             except requests.exceptions.RequestException as e:\n",
    "#                 print(e)\n",
    "#                 time.sleep(2)\n",
    "#                 attempts += 1\n",
    "#     return retry_wrapper\n",
    "\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    \n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    \n",
    "\n",
    "    t1 = threading.Thread(target=monster_website)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    t8 = threading.Thread(target=payscale_india_8)\n",
    "    t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    t12 = threading.Thread(target=talent_india_12)\n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t7.start(),t8.start(),t9.start(),t10.start(),t11.start(),t12.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join()\n",
    "    t7.join(),t8.join(),t9.join(),t10.join(),t11.join(),t12.join()\n",
    "    \n",
    "    #------------------------------------------ End time -------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "\n",
    "# ------------- monster website for united state ---------------\n",
    "def monster_website():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        driver.get(\"https://www.monster.com/salary/\")\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # position=\"java full stack developer\"\n",
    "        # await asyncio.sleep(4)\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        # await asyncio.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        # await asyncio.sleep(2)\n",
    "        average_salary=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "        job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        # await asyncio.sleep(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        time.sleep(2.0)\n",
    "        # await asyncio.sleep(2)\n",
    "        print('2-------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!2222222222222!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        # await asyncio.sleep(0.5)\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        # await asyncio.sleep(0.8)\n",
    "        # select by visible text\n",
    "        select.select_by_visible_text('Per year')\n",
    "        #select by value \n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8.0)\n",
    "        # await asyncio.sleep(0.8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('3------------------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!33333333333333!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        time.sleep(2.0)\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('4------------------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!4444444444444444444!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('5------------------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!55555555555555555!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        time.sleep(2.0)\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        #time.sleep()\n",
    "        print(salary_content)\n",
    "        print('6------------------->',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!666666666666666666!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "#------check+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "def payscale_AUS_Scrap_7():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"_\")\n",
    "        url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # driver.implicitly_wait(0.5)\n",
    "        time.sleep(2.0)\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        #time.sleep()\n",
    "        print('7------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!777777777777777777777!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "#------check+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "def payscale_india_8():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"_\")\n",
    "        url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('8------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!888888888888888888!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "def payscale_US_9():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"_\")\n",
    "        url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('9------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!999999999999999999!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "\n",
    "# ----------------------- check ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        # time.sleep()\n",
    "        print('10------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!10101010101010101010!!!!!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        #time.sleep()\n",
    "        print('11------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!-11-11-11-11-11-!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "\n",
    "# ----------------------- check +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "def talent_india_12():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(1)\n",
    "        # await asyncio.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('12------------------>',salary_content)\n",
    "    except:\n",
    "        print('!!!!!!!!!!!!!-12-12-12-12-12-12-!!!!!!!!!!!!!!!!!')\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "    # app.run(threaded=True ,processes=1)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import threading\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "values={'India':india,'US':US,'Australia':Australia}\n",
    "\n",
    "# ---------------limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position')\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    # ProcessPoolExecutor(5)\n",
    "    asyncio.run(main(name,position))\n",
    "    return values\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    t15 = threading.Thread(target=glassdoor_india_15)\n",
    "    \n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    # t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    # t7.start(),t8.start(),t9.start(),t10.start(),t11.start(),t12.start()\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start(),t15.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    # t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join()\n",
    "    # t7.join(),t8.join(),t9.join(),t10.join(),t11.join(),t12.join()\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join(),t15.join()\n",
    "    \n",
    "    #------------------------------------------ End time -------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "\n",
    "# ------------- monster website for united state ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        driver.get(\"https://www.monster.com/salary/\")\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "        # job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        # print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "        print('1-------->',salary_content)\n",
    "        US.append(salary_content)\n",
    "    except:\n",
    "        print('------- Error - 1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        india.append(salary_content)\n",
    "    except:\n",
    "        print('------- Error - 2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('3------------------->',salary_content)\n",
    "        US.append(salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('4------------------->',salary_content)\n",
    "        Australia.append(salary_content)\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('5------------------->',salary_content)\n",
    "        india.append(salary_content)\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print(salary_content)\n",
    "        print('6------------------->',salary_content.strip())\n",
    "        US.append(salary_content)\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('10------------------>',salary_content)\n",
    "        Australia.append(salary_content)\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('11------------------>',salary_content.strip())\n",
    "        Australia.append(salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        time.sleep(2.0)\n",
    "        print('13-------------->',salary_content.strip())\n",
    "        Australia.append(salary_content.strip())\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        driver.get(\"https://www.salaryexpert.com/salary/area\")\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text\n",
    "        # job_position=driver.find_element_by_xpath(\"/html/body/main/div/div/div[3]/div[1]/div[1]/div[1]/h1\").text\n",
    "        print('14-------------->',salary_content.strip())\n",
    "        US.append(salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def glassdoor_india_15():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[1]/div[1]/div/div/form/input[5]\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[1]/div[1]/div/div/form/input[6]\")\n",
    "        element1.send_keys(\"India\")\n",
    "        time.sleep(10)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        # avg_salary=driver.find_element_by_class_name(\"m-0 css-146zilq ebrouyy2\").text\n",
    "        salary_content=driver.find_element_by_xpath(\"m-0 css-1837fe\").text\n",
    "        print('15-------------->',salary_content.strip())\n",
    "        india.append(salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 15 --------')\n",
    "        pass    \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "# import asyncio\n",
    "import threading\n",
    "import redis\n",
    "from rq import Queue\n",
    "from rq import Worker, Queue, Connection\n",
    "from collections import deque\n",
    "import collections\n",
    "from rq import Queue\n",
    "from rq.job import Job\n",
    "from worker import conn\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "r = redis.Redis()\n",
    "q = Queue(connection=conn)\n",
    "\n",
    "\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "position1=[]\n",
    "values={'Position':position1,'India':india,'US':US,'Australia':Australia}\n",
    "\n",
    "def empty():\n",
    "    india.clear()\n",
    "    US.clear()\n",
    "    Australia.clear()\n",
    "    position1.clear()\n",
    "\n",
    "def queue(name,position):\n",
    "    print('1111111111111111111111111111111111111111111111111111111')\n",
    "    main(name,position)\n",
    " \n",
    "# --------------- limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position')\n",
    "    position1.append(position)\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    empty()\n",
    "    # myQueue = Queue()\n",
    "    # print(enqueue(position))\n",
    "    # collections.deque([main(name,position)])\n",
    "    \n",
    "    # ProcessPoolExecutor(5)\n",
    "    # q.enqueue(main(name,position))\n",
    "    job = q.enqueue_call(func=queue, args=(name,position), result_ttl=5000)\n",
    "    # job = q.enqueue_call(func=queue, args=(name,position))\n",
    "    \n",
    "    \n",
    "    # main(name,position)\n",
    "    print(job.get_id())\n",
    "    return values\n",
    "    \n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    t15 = threading.Thread(target=glassdoor_india_15)\n",
    "    \n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    # t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    # t7.start(),t8.start(),t9.start(),t10.start(),t11.start(),t12.start()\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start(),t15.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    # t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join()\n",
    "    # t7.join(),t8.join(),t9.join(),t10.join(),t11.join(),t12.join()\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join(),t15.join()\n",
    "    \n",
    "    #------------------------------------------ End time -------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "\n",
    "# ------------- monster website for united state ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        driver.get(\"https://www.monster.com/salary/\")\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text\n",
    "        # job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        # print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "        print('1-------->',salary_content)\n",
    "        US.append(salary_content)\n",
    "    except:\n",
    "        print('------- Error - 1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        india.append(salary_content)\n",
    "    except:\n",
    "        print('------- Error - 2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('3------------------->',salary_content)\n",
    "        US.append(salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('4------------------->',salary_content)\n",
    "        Australia.append(salary_content)\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('5------------------->',salary_content)\n",
    "        india.append(salary_content)\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print(salary_content)\n",
    "        print('6------------------->',salary_content.strip())\n",
    "        US.append(salary_content)\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('10------------------>',salary_content)\n",
    "        Australia.append(salary_content)\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        print('11------------------>',salary_content.strip())\n",
    "        Australia.append(salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML')\n",
    "        time.sleep(2.0)\n",
    "        print('13-------------->',salary_content.strip())\n",
    "        Australia.append(salary_content.strip())\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        driver.get(\"https://www.salaryexpert.com/salary/area\")\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text\n",
    "        # job_position=driver.find_element_by_xpath(\"/html/body/main/div/div/div[3]/div[1]/div[1]/div[1]/h1\").text\n",
    "        print('14-------------->',salary_content.strip())\n",
    "        US.append(salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def glassdoor_india_15():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[1]/div[1]/div/div/form/input[5]\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[1]/div[1]/div/div/form/input[6]\")\n",
    "        element1.send_keys(\"India\")\n",
    "        time.sleep(10)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        # avg_salary=driver.find_element_by_class_name(\"m-0 css-146zilq ebrouyy2\").text\n",
    "        salary_content=driver.find_element_by_xpath(\"m-0 css-1837fe\").text\n",
    "        print('15-------------->',salary_content.strip())\n",
    "        india.append(salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 15 --------')\n",
    "        pass    \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import threading\n",
    "import json\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "position1=[]\n",
    "# position={'position':position1}\n",
    "website_values={'Australia':Australia,'India':india,'US':US}\n",
    "all_values={'position':position1,\"website_values\":website_values}\n",
    "\n",
    "# avg_values={'Australia':Australia,'India':india,'US':US}\n",
    "def empty():\n",
    "    india.clear()\n",
    "    US.clear()\n",
    "    Australia.clear()\n",
    "    position1.clear()\n",
    "\n",
    "#--------------- limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    empty()\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position').lower()\n",
    "    position1.append(position)\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    asyncio.run(main(name,position))\n",
    "    return json.dumps(all_values)\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    # t15 = threading.Thread(target=glassdoor_india_15)\n",
    "    \n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    # t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    # t7.start(),t8.start(),t9.start(),t10.start(),t11.start(),t12.start()\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    # t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join()\n",
    "    # t7.join(),t8.join(),t9.join(),t10.join(),t11.join(),t12.join()\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join()\n",
    "    \n",
    "    #------------------------------------------ End time -------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "# ------------- monster website for united state ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        url=\"https://www.monster.com/salary/\"\n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text.strip()\n",
    "        # job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        # print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "        print('1-------->',salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        india.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('3------------------->',salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('4------------------->',salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=((salary_content.replace('₹','')).replace('/mo','')).replace(',','')\n",
    "        print('++++++++++++++++++',v)\n",
    "        salary_content_2 = int(v)*12\n",
    "        print('5------------------->',salary_content_2)\n",
    "        india.append(url+\" == ₹\"+str(salary_content_2))\n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        # print(salary_content)\n",
    "        print('6------------------->',salary_content)\n",
    "        salary_content_2=salary_content.split('/y')[0]\n",
    "        US.append(url+\" == \"+salary_content_2)\n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('***************',salary_content)\n",
    "        v=(salary_content.replace('$','')).replace('k','')\n",
    "        salary_content_2 = (int(v)*1000)\n",
    "        print('10------------------>',salary_content_2)\n",
    "        Australia.append(url+\" == $\"+str(salary_content_2))\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('11------------------>',salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        # time.sleep(2.0)\n",
    "        salary_content_2=salary_content.replace('A','')\n",
    "        print('13-------------->',salary_content_2)\n",
    "        Australia.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        url=\"https://www.salaryexpert.com/salary/area\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text.strip()\n",
    "        # job_position=driver.find_element_by_xpath(\"/html/body/main/div/div/div[3]/div[1]/div[1]/div[1]/h1\").text\n",
    "        \n",
    "        salary_content_2=(salary_content.split('\\n')[1]).split(' (')[0]\n",
    "        print('14-------------->',salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "    \n",
    "    \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import threading\n",
    "import json\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "position1=[]\n",
    "avg_india=[]\n",
    "avg_US=[]\n",
    "avg_Australia=[]\n",
    "# position={'position':position1}\n",
    "\n",
    "# avg_values={'Australia':Australia,'India':india,'US':US}\n",
    "avg_values={}\n",
    "website_values={'Australia':Australia,'India':india,'US':US}\n",
    "all_values={'position':position1,\"website_values\":website_values,'average_value':avg_values}\n",
    "\n",
    "def average_values():\n",
    "    sum_india=[]\n",
    "    for string in avg_india:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('₹','')\n",
    "        sum_india.append(int(new_string))\n",
    "    sum_US=[]\n",
    "    for string in avg_US:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_US.append(int(new_string))\n",
    "    sum_Australia=[]\n",
    "    for string in avg_Australia:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_Australia.append(int(new_string))\n",
    "    \n",
    "    Sum1 = sum(sum_india)\n",
    "    div1=('₹'+str((int(Sum1)/len(avg_india))))\n",
    "    # div1=(str((int(Sum1)/len(avg_india))))\n",
    "    print(avg_india,'-----------------------------------------',str(Sum1),str(div1))\n",
    "    Sum2 = sum(sum_US)\n",
    "    div2=('$'+str((int(Sum2)/len(avg_US))))\n",
    "    print(avg_US,'-----------------------------------------',str(Sum2),str(div2))\n",
    "    Sum3 = sum(sum_Australia)\n",
    "    div3=('$'+str(int(Sum3)/len(avg_Australia)))\n",
    "    print(avg_Australia,'-----------------------------------------',str(Sum3),str(div3))\n",
    "    # global avg_values\n",
    "    # avg_values['Australia']='₹'+\"{:,}\".format(div3.split('.')[1])\n",
    "    avg_values['Australia']=div3.split('.')[1]\n",
    "    avg_values['India']=div1.split('.')[1]\n",
    "    avg_values['US']=div2.split('.')[1]\n",
    "    # avg_values={'Australia':div3,'India':div1,'US':div2}\n",
    "    # avg_values=AVerage_values\n",
    "    print(all_values)\n",
    "def empty():\n",
    "    india.clear()\n",
    "    US.clear()\n",
    "    Australia.clear()\n",
    "    position1.clear()\n",
    "\n",
    "#--------------- limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    empty()\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position').lower()\n",
    "    position1.append(position)\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    asyncio.run(main(name,position))\n",
    "    average_values()\n",
    "    return json.dumps(all_values)\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    # t15 = threading.Thread(target=glassdoor_india_15)\n",
    "    \n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    # t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    # t7.start(),t8.start(),t9.start(),t10.start(),t11.start(),t12.start()\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    # t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join()\n",
    "    # t7.join(),t8.join(),t9.join(),t10.join(),t11.join(),t12.join()\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join()\n",
    "    \n",
    "    #------------------------------------------ End time -------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "# ------------- monster website for united state ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        url=\"https://www.monster.com/salary/\"\n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text.strip()\n",
    "        # job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        # print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "        print('1-------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        avg_india.append(salary_content)\n",
    "        india.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('3------------------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('4------------------->',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=((salary_content.replace('₹','')).replace('/mo','')).replace(',','')\n",
    "        print('++++++++++++++++++',v)\n",
    "        salary_content_2 = int(v)*12\n",
    "        avg_india.append(salary_content_2)\n",
    "        print('5------------------->',salary_content_2)\n",
    "        india.append(url+\" == ₹\"+str(salary_content_2))\n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        # print(salary_content)\n",
    "        print('6------------------->',salary_content)\n",
    "        salary_content_2=salary_content.split('/y')[0]\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2)\n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=(salary_content.replace('$','')).replace('k','')\n",
    "        salary_content_2 = (int(v)*1000)\n",
    "        print('10------------------>',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == $\"+str(salary_content_2))\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('11------------------>',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        # time.sleep(2.0)\n",
    "        salary_content_2=salary_content.replace('A','')\n",
    "        print('13-------------->',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        url=\"https://www.salaryexpert.com/salary/area\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text.strip()\n",
    "        # job_position=driver.find_element_by_xpath(\"/html/body/main/div/div/div[3]/div[1]/div[1]/div[1]/h1\").text\n",
    "        salary_content_2=(salary_content.split('\\n')[1]).split(' (')[0]\n",
    "        print('14-------------->',salary_content_2)\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import threading\n",
    "import json\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "position1=[]\n",
    "avg_india=[]\n",
    "avg_US=[]\n",
    "avg_Australia=[]\n",
    "# position={'position':position1}\n",
    "\n",
    "# avg_values={'Australia':Australia,'India':india,'US':US}\n",
    "avg_values={}\n",
    "website_values={'Australia':Australia,'India':india,'US':US}\n",
    "all_values={'position':position1,\"website_values\":website_values,'average_value':avg_values}\n",
    "\n",
    "def average_values():\n",
    "    sum_india=[]\n",
    "    for string in avg_india:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('₹','')\n",
    "        sum_india.append(int(new_string))\n",
    "    sum_US=[]\n",
    "    for string in avg_US:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_US.append(int(new_string))\n",
    "    sum_Australia=[]\n",
    "    for string in avg_Australia:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_Australia.append(int(new_string))\n",
    "    \n",
    "    Sum1 = sum(sum_india)\n",
    "    div1=('₹'+str(\"{:,}\".format(int(Sum1)/len(avg_india))))\n",
    "    # div1=(str((int(Sum1)/len(avg_india))))\n",
    "    print(avg_india,'-----------------------------------------',str(Sum1),str(div1))\n",
    "    Sum2 = sum(sum_US)\n",
    "    div2=('$'+str(\"{:,}\".format(int(Sum2)/len(avg_US))))\n",
    "    print(avg_US,'-----------------------------------------',str(Sum2),str(div2))\n",
    "    Sum3 = sum(sum_Australia)\n",
    "    div3=('$'+str(\"{:,}\".format(int(Sum3)/len(avg_Australia))))\n",
    "    print(avg_Australia,'-----------------------------------------',str(Sum3),str(div3))\n",
    "    # global avg_values\n",
    "    # avg_values['Australia']='₹'+\"{:,}\".format(div3.split('.')[1])\n",
    "    avg_values['Australia']=div3.split('.')[0]\n",
    "    avg_values['India']=div1.split('.')[0]\n",
    "    avg_values['US']=div2.split('.')[0]\n",
    "    # avg_values={'Australia':div3,'India':div1,'US':div2}\n",
    "    # avg_values=AVerage_values\n",
    "    print(all_values)\n",
    "def empty():\n",
    "    india.clear()\n",
    "    US.clear()\n",
    "    Australia.clear()\n",
    "    position1.clear()\n",
    "\n",
    "#--------------- limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    empty()\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position').lower()\n",
    "    position1.append(position)\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    asyncio.run(main(name,position))\n",
    "    average_values()\n",
    "    return json.dumps(all_values)\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    # t15 = threading.Thread(target=glassdoor_india_15)\n",
    "    \n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    # t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    # t7.start(),t8.start(),t9.start(),t10.start(),t11.start(),t12.start()\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    # t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join()\n",
    "    # t7.join(),t8.join(),t9.join(),t10.join(),t11.join(),t12.join()\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join()\n",
    "    \n",
    "    #------------------------------------------ End time -------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "# ------------- monster website for united state ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        url=\"https://www.monster.com/salary/\"\n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text.strip()\n",
    "        # job_position=driver.find_element_by_class_name(\"salaryJobTitle\").text\n",
    "        # print('MONSTER-website', '[',job_position,']','average salary in UNITED STATES =',average_salary)\n",
    "        print('1-------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        avg_india.append(salary_content)\n",
    "        india.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('3------------------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('4------------------->',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=((salary_content.replace('₹','')).replace('/mo','')).replace(',','')\n",
    "        print('++++++++++++++++++',v)\n",
    "        salary_content_2 = int(v)*12\n",
    "        avg_india.append(salary_content_2)\n",
    "        print('5------------------->',salary_content_2)\n",
    "        india.append(url+\" == ₹\"+str(salary_content_2))\n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        # print(salary_content)\n",
    "        print('6------------------->',salary_content)\n",
    "        salary_content_2=salary_content.split('/y')[0]\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2)\n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=(salary_content.replace('$','')).replace('k','')\n",
    "        salary_content_2 = (int(v)*1000)\n",
    "        print('10------------------>',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == $\"+str(salary_content_2))\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('11------------------>',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        # time.sleep(2.0)\n",
    "        salary_content_2=salary_content.replace('A','')\n",
    "        print('13-------------->',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        url=\"https://www.salaryexpert.com/salary/area\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text.strip()\n",
    "        # job_position=driver.find_element_by_xpath(\"/html/body/main/div/div/div[3]/div[1]/div[1]/div[1]/h1\").text\n",
    "        salary_content_2=(salary_content.split('\\n')[1]).split(' (')[0]\n",
    "        print('14-------------->',salary_content_2)\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove\n",
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import threading\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "skill_extraction=[]\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "position1=[]\n",
    "avg_india=[]\n",
    "avg_US=[]\n",
    "avg_Australia=[]\n",
    "avg_values={}\n",
    "\n",
    "website_values={'Australia':Australia,'India':india,'US':US}\n",
    "all_values={'position':position1,\"website_values\":website_values,'average_value':avg_values,'Required_Skills':skill_extraction}\n",
    "\n",
    "def average_values():\n",
    "    sum_india=[]\n",
    "    for string in avg_india:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('₹','')\n",
    "        sum_india.append(int(new_string))\n",
    "    sum_US=[]\n",
    "    for string in avg_US:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_US.append(int(new_string))\n",
    "    sum_Australia=[]\n",
    "    for string in avg_Australia:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_Australia.append(int(new_string))\n",
    "    Sum1 = sum(sum_india)\n",
    "    if len(avg_india) != 0:\n",
    "        div1=('₹'+str(\"{:,}\".format(int(Sum1)/len(avg_india))))\n",
    "        avg_values['India']=div1.split('.')[0]\n",
    "    else:\n",
    "        avg_values['India']=0\n",
    "    Sum2 = sum(sum_US)\n",
    "    if len(avg_US) != 0:\n",
    "        div2=('$'+str(\"{:,}\".format(int(Sum2)/len(avg_US))))\n",
    "        avg_values['US']=div2.split('.')[0]\n",
    "    else:\n",
    "        avg_values['US']=0\n",
    "    Sum3 = sum(sum_Australia)\n",
    "    if len(avg_Australia) != 0:\n",
    "        div3=('$'+str(\"{:,}\".format(int(Sum3)/len(avg_Australia))))\n",
    "        avg_values['Australia']=div3.split('.')[0]\n",
    "    else:\n",
    "        avg_values['Australia']=0\n",
    "    print(all_values)\n",
    "    \n",
    "def empty():\n",
    "    india.clear()\n",
    "    US.clear()\n",
    "    Australia.clear()\n",
    "    position1.clear()\n",
    "    avg_india.clear()\n",
    "    avg_US.clear()\n",
    "    avg_Australia.clear()\n",
    "    skill_extraction.clear()\n",
    "    \n",
    "#--------------- limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    empty()\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position').lower()\n",
    "    position1.append(position)\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    asyncio.run(main(name,position))\n",
    "    average_values()\n",
    "    return json.dumps(all_values)\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    print(name)\n",
    "    print(position)\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    t15 = threading.Thread(target=skills_extraction)\n",
    "    \n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start(),t15.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join(),t15.join()\n",
    "    \n",
    "    #------------------------------------------ End time ----------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "# ---------------  monster website for united state  ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        url=\"https://www.monster.com/salary/\"\n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text.strip()\n",
    "        print('1-------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        avg_india.append(salary_content)\n",
    "        india.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('3------------------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('4------------------->',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=((salary_content.replace('₹','')).replace('/mo','')).replace(',','')\n",
    "        salary_content_2 = int(v)*12\n",
    "        avg_india.append(salary_content_2)\n",
    "        print('5------------------->',salary_content_2)\n",
    "        india.append(url+\" == ₹\"+str(salary_content_2))\n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('6------------------->',salary_content)\n",
    "        salary_content_2=salary_content.split('/y')[0]\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2)\n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=(salary_content.replace('$','')).replace('k','')\n",
    "        salary_content_2 = (int(v)*1000)\n",
    "        print('10------------------>',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == $\"+str(salary_content_2))\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('11------------------>',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        salary_content_2=salary_content.replace('A','')\n",
    "        print('13-------------->',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        url=\"https://www.salaryexpert.com/salary/area\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text.strip()\n",
    "        salary_content_2=(salary_content.split('\\n')[1]).split(' (')[0]\n",
    "        print('14-------------->',salary_content_2)\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "\n",
    "def skills_extraction():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        driver.find_element_by_link_text(\"Skills\").click()\n",
    "        time.sleep(5.0)\n",
    "        salary = driver.find_element_by_xpath(\"//ul[@class='css-vurnku eu4oa1w0']\")\n",
    "        skill=salary.text\n",
    "        skill_list = skill.split(\"\\n\")\n",
    "        print(skill_list)\n",
    "        skill_extraction.append(skill_list)\n",
    "    except:\n",
    "        try:\n",
    "            driver=webbrowser()\n",
    "            replaced_position=position.replace(' ',\"-\")\n",
    "            url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(0.5)\n",
    "            salary = driver.find_element_by_xpath(\"//div[@class='css-1r274bm']\")\n",
    "            skill=salary.text\n",
    "            skill_list = skill.split(\"\\n\")\n",
    "            print(skill_list)\n",
    "            skill_extraction.append(skill_list)\n",
    "        except:\n",
    "            pass\n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from redis import Redis\n",
    "from os import remove\n",
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import threading\n",
    "import json\n",
    "from rq import Queue\n",
    "from pymongo import MongoClient\n",
    "# import json\n",
    "# from bson import ObjectId\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "skill_extraction=[]\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "position1=[]\n",
    "avg_india=[]\n",
    "avg_US=[]\n",
    "avg_Australia=[]\n",
    "avg_values={}\n",
    "\n",
    "# pool = redis.ConnectionPool(host='localhost', port=6379, db=0)\n",
    "\n",
    "# r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "# r = redis.Redis()\n",
    "# queue = Queue(connection=r)\n",
    "# q = Queue(connection=Redis())\n",
    "\n",
    "\n",
    "website_values={'Australia':Australia,'India':india,'US':US}\n",
    "all_values={'position':position1,\"website_\":website_values,'average_salary':avg_values,'Required_Skills':skill_extraction}\n",
    "# mongodb_values=all_values\n",
    "mongodb_values={'position':all_values}\n",
    "\n",
    "\n",
    "\n",
    "# client = MongoClient(\"mongodb://localhosjt:27017/\")j\n",
    "client = MongoClient('localhost', 27017)\n",
    "mydatabase = client['testdb']\n",
    "mycollection = mydatabase['testcol']\n",
    "rec=mydatabase.testcol.insert_one(mongodb_values)\n",
    "\n",
    "\n",
    "\n",
    "def average_values():\n",
    "    sum_india=[]\n",
    "    for string in avg_india:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('₹','')\n",
    "        sum_india.append(int(new_string))\n",
    "    sum_US=[]\n",
    "    for string in avg_US:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_US.append(int(new_string))\n",
    "    sum_Australia=[]\n",
    "    for string in avg_Australia:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_Australia.append(int(new_string))\n",
    "    Sum1 = sum(sum_india)\n",
    "    if len(avg_india) != 0:\n",
    "        div1=('₹'+str(\"{:,}\".format(int(Sum1)/len(avg_india))))\n",
    "        avg_values['India']=div1.split('.')[0]\n",
    "    else:\n",
    "        avg_values['India']=0\n",
    "    Sum2 = sum(sum_US)\n",
    "    if len(avg_US) != 0:\n",
    "        div2=('$'+str(\"{:,}\".format(int(Sum2)/len(avg_US))))\n",
    "        avg_values['US']=div2.split('.')[0]\n",
    "    else:\n",
    "        avg_values['US']=0\n",
    "    Sum3 = sum(sum_Australia)\n",
    "    if len(avg_Australia) != 0:\n",
    "        div3=('$'+str(\"{:,}\".format(int(Sum3)/len(avg_Australia))))\n",
    "        avg_values['Australia']=div3.split('.')[0]\n",
    "    else:\n",
    "        avg_values['Australia']=0\n",
    "    print(all_values)\n",
    "    \n",
    "def empty():\n",
    "    india.clear()\n",
    "    US.clear()\n",
    "    Australia.clear()\n",
    "    position1.clear()\n",
    "    avg_india.clear()\n",
    "    avg_US.clear()\n",
    "    avg_Australia.clear()\n",
    "    skill_extraction.clear()\n",
    "    \n",
    "#--------------- limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    empty()\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position').lower()\n",
    "    position1.append(position)\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    # empty()\n",
    "    # job = queue.enqueue(main, position)\n",
    "    asyncio.run(main(name,position))\n",
    "    average_values()\n",
    "    # return json.JSONEncoder(all_values, cls=JSONEncoder)\n",
    "    # return json.JSONEncoder(all_values)\n",
    "    # return json.encode(all_values, cls=JSONEncoder)\n",
    "    return json.dumps(all_values)\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    # print(name)\n",
    "    print(position)\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    t15 = threading.Thread(target=skills_extraction)\n",
    "    \n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start(),t15.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join(),t15.join()\n",
    "    \n",
    "    #------------------------------------------ End time ----------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "# ---------------  monster website for united state  ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        url=\"https://www.monster.com/salary/\"\n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text.strip()\n",
    "        print('1-------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        avg_india.append(salary_content)\n",
    "        india.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('3------------------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('4------------------->',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=((salary_content.replace('₹','')).replace('/mo','')).replace(',','')\n",
    "        salary_content_2 = int(v)*12\n",
    "        avg_india.append(salary_content_2)\n",
    "        print('5------------------->',salary_content_2)\n",
    "        india.append(url+\" == ₹\"+str(salary_content_2))\n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('6------------------->',salary_content)\n",
    "        salary_content_2=salary_content.split('/y')[0]\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2)\n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=(salary_content.replace('$','')).replace('k','')\n",
    "        salary_content_2 = (int(v)*1000)\n",
    "        print('10------------------>',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == $\"+str(salary_content_2))\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('11------------------>',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        salary_content_2=salary_content.replace('A','')\n",
    "        print('13-------------->',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        url=\"https://www.salaryexpert.com/salary/area\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text.strip()\n",
    "        salary_content_2=(salary_content.split('\\n')[1]).split(' (')[0]\n",
    "        print('14-------------->',salary_content_2)\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "\n",
    "def skills_extraction():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        driver.find_element_by_link_text(\"Skills\").click()\n",
    "        time.sleep(5.0)\n",
    "        salary = driver.find_element_by_xpath(\"//ul[@class='css-vurnku eu4oa1w0']\")\n",
    "        skill=salary.text\n",
    "        skill_list = skill.split(\"\\n\")\n",
    "        print(skill_list)\n",
    "        for skill in skill_list:\n",
    "            skill_extraction.append(skill)\n",
    "        # skill_extraction.append(skill_list)\n",
    "    except:\n",
    "        try:\n",
    "            driver=webbrowser()\n",
    "            replaced_position=position.replace(' ',\"-\")\n",
    "            url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(0.5)\n",
    "            salary = driver.find_element_by_xpath(\"//div[@class='css-1r274bm']\")\n",
    "            skill=salary.text\n",
    "            skill_list = skill.split(\"\\n\")\n",
    "            print(skill_list)\n",
    "            for skill in skill_list:\n",
    "                skill_extraction.append(skill)\n",
    "            # skill_extraction.append(skill_list)\n",
    "        except:\n",
    "            pass\n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from os import remove\n",
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import threading\n",
    "import json\n",
    "from rq import Queue\n",
    "from pymongo import MongoClient\n",
    "import logging\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "skill_extraction=[]\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "position1=[]\n",
    "avg_india=[]\n",
    "avg_US=[]\n",
    "avg_Australia=[]\n",
    "avg_values={}\n",
    "\n",
    "# pool = redis.ConnectionPool(host='localhost', port=6379, db=0)\n",
    "\n",
    "# r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "# r = redis.Redis()\n",
    "# queue = Queue(connection=r)\n",
    "# q = Queue(connection=Redis())\n",
    "\n",
    "logging.basicConfig(filename='Salary_Log_Book.log', level=logging.INFO)\n",
    "\n",
    "website_values={'Australia':Australia,'India':india,'US':US}\n",
    "all_values={\"position\":position1,\"website_salary\":website_values,\"average_salary\":avg_values,\"Required_Skills\":skill_extraction}\n",
    "# mongodb_values={'position':all_values}\n",
    "\n",
    "\n",
    "def mongodb(name):\n",
    "    values={\"Name - \"+name :all_values}\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    mydatabase = client['testdb']\n",
    "    mydatabase.testcol.insert_one(values)\n",
    "\n",
    "def average_values():\n",
    "    sum_india=[]\n",
    "    for string in avg_india:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('₹','')\n",
    "        sum_india.append(int(new_string))\n",
    "    sum_US=[]\n",
    "    for string in avg_US:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_US.append(int(new_string))\n",
    "    sum_Australia=[]\n",
    "    for string in avg_Australia:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_Australia.append(int(new_string))\n",
    "    Sum1 = sum(sum_india)\n",
    "    if len(avg_india) != 0:\n",
    "        div1=('₹'+str(\"{:,}\".format(int(Sum1)/len(avg_india))))\n",
    "        avg_values['India']=div1.split('.')[0]\n",
    "    else:\n",
    "        avg_values['India']=0\n",
    "    Sum2 = sum(sum_US)\n",
    "    if len(avg_US) != 0:\n",
    "        div2=('$'+str(\"{:,}\".format(int(Sum2)/len(avg_US))))\n",
    "        avg_values['US']=div2.split('.')[0]\n",
    "    else:\n",
    "        avg_values['US']=0\n",
    "    Sum3 = sum(sum_Australia)\n",
    "    if len(avg_Australia) != 0:\n",
    "        div3=('$'+str(\"{:,}\".format(int(Sum3)/len(avg_Australia))))\n",
    "        avg_values['Australia']=div3.split('.')[0]\n",
    "    else:\n",
    "        avg_values['Australia']=0\n",
    "    print(all_values)\n",
    "    \n",
    "    \n",
    "def empty():\n",
    "    india.clear()\n",
    "    US.clear()\n",
    "    Australia.clear()\n",
    "    position1.clear()\n",
    "    avg_india.clear()\n",
    "    avg_US.clear()\n",
    "    avg_Australia.clear()\n",
    "    skill_extraction.clear()\n",
    "    \n",
    "#--------------- limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    empty()\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position').lower()\n",
    "    position1.append(position)\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-')\n",
    "    asyncio.run(main(name,position))\n",
    "    average_values()\n",
    "    mongodb(name)\n",
    "    return json.dumps(all_values)\n",
    "\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "async def main(name,position):\n",
    "    # print(name)\n",
    "    print(position)\n",
    "    # global position1\n",
    "    # position1=position\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    t15 = threading.Thread(target=skills_extraction)\n",
    "    \n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start(),t15.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join(),t15.join()\n",
    "    \n",
    "    #------------------------------------------ End time ----------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    print('end')\n",
    "\n",
    "# ---------------  monster website for united state  ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        url=\"https://www.monster.com/salary/\"\n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text.strip()\n",
    "        print('1-------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        avg_india.append(salary_content)\n",
    "        india.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('3------------------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('4------------------->',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=((salary_content.replace('₹','')).replace('/mo','')).replace(',','')\n",
    "        salary_content_2 = int(v)*12\n",
    "        avg_india.append(salary_content_2)\n",
    "        print('5------------------->',salary_content_2)\n",
    "        india.append(url+\" == ₹\"+str(salary_content_2))\n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('6------------------->',salary_content)\n",
    "        salary_content_2=salary_content.split('/y')[0]\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2)\n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=(salary_content.replace('$','')).replace('k','')\n",
    "        salary_content_2 = (int(v)*1000)\n",
    "        print('10------------------>',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == $\"+str(salary_content_2))\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('11------------------>',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        salary_content_2=salary_content.replace('A','')\n",
    "        print('13-------------->',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        url=\"https://www.salaryexpert.com/salary/area\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text.strip()\n",
    "        salary_content_2=(salary_content.split('\\n')[1]).split(' (')[0]\n",
    "        print('14-------------->',salary_content_2)\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "\n",
    "\n",
    "def skills_extraction():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        driver.find_element_by_link_text(\"Skills\").click()\n",
    "        time.sleep(5.0)\n",
    "        salary = driver.find_element_by_xpath(\"//ul[@class='css-vurnku eu4oa1w0']\")\n",
    "        skill=salary.text\n",
    "        skill_list = skill.split(\"\\n\")\n",
    "        print(skill_list)\n",
    "        for skill in skill_list:\n",
    "            skill_extraction.append(skill)\n",
    "    except:\n",
    "        try:\n",
    "            driver=webbrowser()\n",
    "            replaced_position=position.replace(' ',\"-\")\n",
    "            url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(0.5)\n",
    "            salary = driver.find_element_by_xpath(\"//div[@class='css-1r274bm']\")\n",
    "            skill=salary.text\n",
    "            skill_list = skill.split(\"\\n\")\n",
    "            print(skill_list)\n",
    "            for skill in skill_list:\n",
    "                skill_extraction.append(skill)\n",
    "        except:\n",
    "            pass\n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from os import remove\n",
    "from flask import Flask,request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "import threading\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import logging\n",
    "from rq import Queue\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "skill_extraction=[]\n",
    "india=[]\n",
    "US=[]\n",
    "Australia=[]\n",
    "position1=[]\n",
    "avg_india=[]\n",
    "avg_US=[]\n",
    "avg_Australia=[]\n",
    "avg_values={}\n",
    "\n",
    "# r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "# r = redis.Redis()\n",
    "# q = Queue(connection=r)\n",
    "q = Queue(connection=redis.Redis())\n",
    "\n",
    "#  ----------------------- store the logger history -------------------------------\n",
    "# logging.basicConfig(filename='Salary_Log_Book.log', level=logging.DEBUG)\n",
    "\n",
    "# logging.basicConfig(filename='Salary_Log_Book.log', level=logging.INFO)\n",
    "\n",
    "\n",
    "website_values={'Australia':Australia,'India':india,'US':US}\n",
    "all_values={\"position\":position1,\"website_salary\":website_values,\"average_salary\":avg_values,\"Required_Skills\":skill_extraction}\n",
    "\n",
    "\n",
    "def mongodb(name):\n",
    "    values={\"Name - \"+name :all_values}\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    mydatabase = client['testdb']\n",
    "    mydatabase.testcol.insert_one(values)\n",
    "\n",
    "\n",
    "def average_values():\n",
    "    sum_india=[]\n",
    "    for string in avg_india:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('₹','')\n",
    "        sum_india.append(int(new_string))\n",
    "    sum_US=[]\n",
    "    for string in avg_US:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_US.append(int(new_string))\n",
    "    sum_Australia=[]\n",
    "    for string in avg_Australia:\n",
    "        new_string = (str(string).replace(\",\",\"\")).replace('$','')\n",
    "        sum_Australia.append(int(new_string))\n",
    "    Sum1 = sum(sum_india)\n",
    "    if len(avg_india) != 0:\n",
    "        div1=('₹'+str(\"{:,}\".format(int(Sum1)/len(avg_india))))\n",
    "        avg_values['India']=div1.split('.')[0]\n",
    "    else:\n",
    "        avg_values['India']=0\n",
    "    Sum2 = sum(sum_US)\n",
    "    if len(avg_US) != 0:\n",
    "        div2=('$'+str(\"{:,}\".format(int(Sum2)/len(avg_US))))\n",
    "        avg_values['US']=div2.split('.')[0]\n",
    "    else:\n",
    "        avg_values['US']=0\n",
    "    Sum3 = sum(sum_Australia)\n",
    "    if len(avg_Australia) != 0:\n",
    "        div3=('$'+str(\"{:,}\".format(int(Sum3)/len(avg_Australia))))\n",
    "        avg_values['Australia']=div3.split('.')[0]\n",
    "    else:\n",
    "        avg_values['Australia']=0\n",
    "    print(all_values)\n",
    "    \n",
    "    \n",
    "def empty():\n",
    "    india.clear()\n",
    "    US.clear()\n",
    "    Australia.clear()\n",
    "    position1.clear()\n",
    "    avg_india.clear()\n",
    "    avg_US.clear()\n",
    "    avg_Australia.clear()\n",
    "    skill_extraction.clear()\n",
    "    \n",
    "#--------------- limit the number request can be made in flask --------------------------\n",
    "@app.route('/trigger',methods=['POST'])\n",
    "def trigger():\n",
    "    empty()\n",
    "    data = request.get_json()\n",
    "    global position\n",
    "    position =data.get('position').lower()\n",
    "    # position1.append(position)\n",
    "    global name\n",
    "    name = data.get('name')\n",
    "    print(name)\n",
    "    print('-'+position+'-') \n",
    "    # main(name,position)\n",
    "    print('---------------')\n",
    "    job = q.enqueue('main',(name,position))\n",
    "    # job = q.enqueue(main,position)\n",
    "    \n",
    "    # return f\"Task ({job.id}) added to queue at {job.enqueued_at}\"\n",
    "    # average_values()\n",
    "    return job.result\n",
    "    \n",
    "    # for line in iter(d, None):\n",
    "    #     c=line\n",
    "    # main(name,position)\n",
    "    # average_values()\n",
    "    # return json.dumps(all_values)\n",
    "\n",
    "\n",
    "# --------------- chrome browser ----------------\n",
    "def webbrowser():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    time.sleep(2)\n",
    "    # options.add_extension('adblocker.crx')  \n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "# ------ main function assign the asynchronous function into task ---------\n",
    "def main(name,position):\n",
    "    print('---------------')\n",
    "    print(name)\n",
    "    print(position)\n",
    "    position1.append(position)\n",
    "    # global position1\n",
    "    # position1=position\n",
    "    # ----------------------------------- starting time ---------------------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "    t1 = threading.Thread(target=monster_website_US_1)\n",
    "    t2 = threading.Thread(target=glassdoor_india_2)\n",
    "    t3 = threading.Thread(target=indeed_us_3)\n",
    "    t4 = threading.Thread(target=linkedin_aus_4)\n",
    "    t5 = threading.Thread(target=linkedin_india_5)\n",
    "    t6 = threading.Thread(target=linkedin_us_6)\n",
    "    # t7 = threading.Thread(target=payscale_AUS_Scrap_7)\n",
    "    # t8 = threading.Thread(target=payscale_india_8)\n",
    "    # t9 = threading.Thread(target=payscale_US_9)\n",
    "    t10 = threading.Thread(target=seek_scrapy_aus_10)\n",
    "    t11 = threading.Thread(target=talent_aus_scrapy_11)\n",
    "    # t12 = threading.Thread(target=talent_india_12)\n",
    "    t13 = threading.Thread(target=glassdoor_AUS_13)\n",
    "    t14 = threading.Thread(target=sales_expect_US_14)\n",
    "    t15 = threading.Thread(target=skills_extraction)\n",
    "    \n",
    "    # --------------start the function ---------------------------\n",
    "    t1.start(),t2.start(),t3.start(),t4.start(),t5.start(),t6.start(),\n",
    "    t10.start(),t11.start(),t13.start(),t14.start(),t15.start()\n",
    "    \n",
    "    # -------------- wait till the function executed ----------------\n",
    "    t1.join(),t2.join(),t3.join(),t4.join(),t5.join(),t6.join(),t10.join(),t11.join(),t13.join(),t14.join(),t15.join()\n",
    "    \n",
    "    #------------------------------------------ End time ----------------------------------\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    mongodb(name)\n",
    "    print('end')\n",
    "    average_values()\n",
    "    return json.dumps(all_values)\n",
    "\n",
    "# ---------------  monster website for united state  ---------------\n",
    "def monster_website_US_1():\n",
    "    driver=webbrowser()\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        url=\"https://www.monster.com/salary/\"\n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(4)\n",
    "        element = driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[1]/div[2]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/div[1]/main/section[1]/div/div/div/div/div[2]/div[2]/span/input\")\n",
    "        element1.send_keys(\"United States Military Acade, NY\")\n",
    "        time.sleep(15)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        element2=driver.find_element_by_id(\"doQuickSearch2\")\n",
    "        element2.click()\n",
    "        time.sleep(2)\n",
    "        salary_content=driver.find_element_by_class_name(\"avg-salary\").text.strip()\n",
    "        print('1-------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -1----- ')\n",
    "        pass\n",
    "\n",
    "#  ---------------------   glassdoor India   -----------------------\n",
    "def glassdoor_india_2():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/chennai-'+replaced_position+'-salary-SRCH_IL.0,7_IM1067_KO8,25.htm?'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        time.sleep(2.0)\n",
    "        print('2-------->',salary_content)\n",
    "        avg_india.append(salary_content)\n",
    "        india.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error -2----- ')\n",
    "        pass\n",
    "\n",
    "def indeed_us_3():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '-')\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        select = Select(driver.find_element_by_xpath(\"//select[@name='payPeriodSelect']\"))\n",
    "        time.sleep(0.8)\n",
    "        select.select_by_visible_text('Per year')\n",
    "        select.select_by_value('YEARLY')\n",
    "        time.sleep(8)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='css-cd2ps3 eu4oa1w0']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('3------------------->',salary_content)\n",
    "        avg_US.append(salary_content)\n",
    "        US.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 3 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_aus_4():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ', '%20')\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=au&geoId=101452733&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('4------------------->',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content)\n",
    "    except:\n",
    "        print('------- Error - 4 -------- ')\n",
    "        pass\n",
    "\n",
    "# ------monthly salary--------\n",
    "def linkedin_india_5():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"%2B\")\n",
    "        url = 'https://www.linkedin.com/salary/search?countryCode=in&geoId=102713980&keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=((salary_content.replace('₹','')).replace('/mo','')).replace(',','')\n",
    "        salary_content_2 = int(v)*12\n",
    "        avg_india.append(salary_content_2)\n",
    "        print('5------------------->',salary_content_2)\n",
    "        india.append(url+\" == ₹\"+str(salary_content_2))\n",
    "    except:\n",
    "        print('------- Error - 5 -------- ')\n",
    "        pass\n",
    "\n",
    "def linkedin_us_6():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://www.linkedin.com/salary/search?keywords='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        time.sleep(2.0)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='searchTopCard__baseCompensation']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('6------------------->',salary_content)\n",
    "        salary_content_2=salary_content.split('/y')[0]\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2)\n",
    "    except:\n",
    "        print('------- Error - 6 -------- ')\n",
    "        pass\n",
    "\n",
    "# def payscale_AUS_Scrap_7():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/AU/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(2.0)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('7------------------>',salary_content)\n",
    "#         Australia.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 7 -------- ')\n",
    "#         pass\n",
    "\n",
    "# def payscale_india_8():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/IN/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('8------------------>',salary_content)\n",
    "#         india.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 8 --------')\n",
    "#         pass\n",
    "\n",
    "# def payscale_US_9():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"_\")\n",
    "#         url = 'https://www.payscale.com/research/US/Job='+replaced_position+'/Salary'\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         driver.implicitly_wait(0.5)\n",
    "#         salary = driver.find_element_by_xpath(\"//span[@class='paycharts__value']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('9------------------>',salary_content)\n",
    "#         US.append(salary_content)\n",
    "#     except:\n",
    "#         print('------- Error - 9 --------')\n",
    "#         pass\n",
    "\n",
    "def seek_scrapy_aus_10():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\").lower()\n",
    "        url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        salary = driver.find_element_by_xpath(\"//div[@data-testid='salary-value']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        v=(salary_content.replace('$','')).replace('k','')\n",
    "        salary_content_2 = (int(v)*1000)\n",
    "        print('10------------------>',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == $\"+str(salary_content_2))\n",
    "        \n",
    "    except:\n",
    "        print('------- Error - 10 --------')\n",
    "        pass\n",
    "\n",
    "def talent_aus_scrapy_11():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"+\")\n",
    "        url = 'https://au.talent.com/salary?job='+replaced_position\n",
    "        driver.get(url)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        print('11------------------>',salary_content)\n",
    "        avg_Australia.append(salary_content)\n",
    "        Australia.append(url+\" == \"+salary_content.strip())\n",
    "    except:\n",
    "        print('------- Error - 11 --------')\n",
    "        pass\n",
    "\n",
    "# def talent_india_12():\n",
    "#     try:\n",
    "#         driver=webbrowser()\n",
    "#         replaced_position=position.replace(' ',\"+\")\n",
    "#         url = 'https://in.talent.com/salary?job=',replaced_position\n",
    "#         driver.get(url)\n",
    "#         driver.switch_to.window(driver.window_handles[0])\n",
    "#         time.sleep(1)\n",
    "#         salary = driver.find_element_by_xpath(\"//div[@class='c-card__stats-mainNumber timeBased']\")\n",
    "#         salary_content = salary.get_attribute('innerHTML')\n",
    "#         print('12------------------>',salary_content.strip())\n",
    "#     except:\n",
    "#         print('------- Error - 12 --------')\n",
    "#         pass\n",
    "\n",
    "def glassdoor_AUS_13():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.glassdoor.co.in/Salaries/australia-'+replaced_position+'-salary-SRCH_IL.0,9_IN16_KO10,27.htm?clickSource=searchBtn'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        salary = driver.find_element_by_xpath(\"//span[@class='m-0 css-146zilq ebrouyy2']\")\n",
    "        salary_content = salary.get_attribute('innerHTML').strip()\n",
    "        salary_content_2=salary_content.replace('A','')\n",
    "        print('13-------------->',salary_content_2)\n",
    "        avg_Australia.append(salary_content_2)\n",
    "        Australia.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 13 --------')\n",
    "        pass\n",
    "    \n",
    "def sales_expect_US_14():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        url=\"https://www.salaryexpert.com/salary/area\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        element=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[1]/span/input\")\n",
    "        element.send_keys(position)\n",
    "        element1=driver.find_element_by_xpath(\"/html/body/main/div/div[1]/div[1]/div/form/div[1]/div[2]/span/input\")\n",
    "        element1.send_keys(\"Australia\")\n",
    "        time.sleep(5)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "        salary_content=driver.find_element_by_class_name(\"base\").text.strip()\n",
    "        salary_content_2=(salary_content.split('\\n')[1]).split(' (')[0]\n",
    "        print('14-------------->',salary_content_2)\n",
    "        avg_US.append(salary_content_2)\n",
    "        US.append(url+\" == \"+salary_content_2.strip())\n",
    "    except:\n",
    "        print('------- Error - 14 --------')\n",
    "        pass\n",
    "\n",
    "\n",
    "def skills_extraction():\n",
    "    try:\n",
    "        driver=webbrowser()\n",
    "        replaced_position=position.replace(' ',\"-\")\n",
    "        url = 'https://www.indeed.com/career/'+replaced_position+'/salaries'\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(0.5)\n",
    "        driver.find_element_by_link_text(\"Skills\").click()\n",
    "        time.sleep(5.0)\n",
    "        salary = driver.find_element_by_xpath(\"//ul[@class='css-vurnku eu4oa1w0']\")\n",
    "        skill=salary.text\n",
    "        skill_list = skill.split(\"\\n\")\n",
    "        print(skill_list)\n",
    "        for skill in skill_list:\n",
    "            skill_extraction.append(skill)\n",
    "    except:\n",
    "        try:\n",
    "            driver=webbrowser()\n",
    "            replaced_position=position.replace(' ',\"-\")\n",
    "            url = 'https://www.seek.com.au/career-advice/role/'+replaced_position\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(0.5)\n",
    "            salary = driver.find_element_by_xpath(\"//div[@class='css-1r274bm']\")\n",
    "            skill=salary.text\n",
    "            skill_list = skill.split(\"\\n\")\n",
    "            print(skill_list)\n",
    "            for skill in skill_list:\n",
    "                skill_extraction.append(skill)\n",
    "        except:\n",
    "            pass\n",
    "if __name__ == '__main__':\n",
    "    app.run()   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
